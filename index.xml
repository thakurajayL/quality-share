<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Quality Share: A Curated Library for Engineers</title><link>https://thakurajayL.github.io/quality-share/</link><description>Recent content on Quality Share: A Curated Library for Engineers</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Mon, 20 Oct 2025 22:00:00 -0400</lastBuildDate><atom:link href="https://thakurajayL.github.io/quality-share/index.xml" rel="self" type="application/rss+xml"/><item><title>Privacy Policy</title><link>https://thakurajayL.github.io/quality-share/privacy-policy/</link><pubDate>Mon, 20 Oct 2025 22:00:00 -0400</pubDate><guid>https://thakurajayL.github.io/quality-share/privacy-policy/</guid><description>&lt;h1 id="privacy-policy"&gt;Privacy Policy&lt;/h1&gt;
&lt;p&gt;This is a placeholder for our privacy policy. More detailed information will be added here soon.&lt;/p&gt;</description></item><item><title>Glossary</title><link>https://thakurajayL.github.io/quality-share/glossary/</link><pubDate>Mon, 20 Oct 2025 16:00:00 -0400</pubDate><guid>https://thakurajayL.github.io/quality-share/glossary/</guid><description>&lt;p&gt;This page will contain a glossary of common terms used in the project. More content will be added here soon.&lt;/p&gt;
&lt;h2 id="choosing-a-client-server-communication-mode"&gt;Choosing a Client-Server Communication Mode&lt;/h2&gt;
&lt;h3 id="polling"&gt;Polling&lt;/h3&gt;
&lt;p&gt;Polling is a technique where a client repeatedly sends requests to a server at regular intervals to check for new data. If there is no new data, the server sends an empty response. This is a simple but inefficient method, as it can generate a lot of unnecessary network traffic.&lt;/p&gt;</description></item><item><title>About Quality Share</title><link>https://thakurajayL.github.io/quality-share/about/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/about/</guid><description>&lt;h2 id="our-mission"&gt;Our Mission&lt;/h2&gt;
&lt;p&gt;Quality Share aims to be your trusted librarian for high-quality technical content, especially for professionals interested in distributed systems. In a world of information overload, we provide a curated selection of the best technical articles from top companies and experts, complete with concise summaries and key takeaways to accelerate learning and discovery.&lt;/p&gt;
&lt;h2 id="our-philosophy-quality-is-everything"&gt;Our Philosophy: Quality is Everything&lt;/h2&gt;
&lt;p&gt;We prioritize exceptional quality over a consistent publishing schedule. Content is only shared when it meets an exceptionally high standard. Our goal is to help software architects and senior engineers stay current with real-world, in-depth technical solutions without the noise.&lt;/p&gt;</description></item><item><title>Branching in a Sapling Monorepo</title><link>https://thakurajayL.github.io/quality-share/posts/branching-in-a-sapling-monorepo/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/branching-in-a-sapling-monorepo/</guid><description>Sapling is an open-source source control system used at Meta for managing a large monorepo. The system introduces directory branching as a solution to the challenges of managing multiple versions of code in a monorepo. Directory branching allows for branching at the directory level, enabling cherry-picking and merging changes between directories while maintaining a linear commit graph at the monorepo level. This approach addresses scalability issues associated with full-repo branching and provides a flexible solution for managing code versions. The system has been well-received by engineering teams at Meta, with various use cases identified for adopting directory branching. Future plans include integrating Git repositories into the monorepo using a lightweight migration mechanism.</description></item><item><title>Branching in a Sapling Monorepo</title><link>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251021190026/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251021190026/</guid><description>Sapling is an open-source source control system used at Meta for managing a large monorepo. The system introduces directory branching as a solution to the challenges of managing multiple versions of code in a monorepo. Directory branching allows for branching at the directory level, enabling cherry-picking and merging changes between directories while maintaining a linear commit graph at the monorepo level. This approach addresses scalability issues associated with full-repo branching and provides a flexible solution for managing code versions. The system has been well-received by engineering teams at Meta, with various use cases identified for adopting directory branching. Future plans include integrating Git repositories into the monorepo using a lightweight migration mechanism.</description></item><item><title>Google Pro Tip Use Back Of The Envelope Calculations</title><link>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251022171845/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251022171845/</guid><description>The text discusses using back-of-the-envelope calculations to evaluate different design alternatives, specifically focusing on a scenario of generating an image results page with 30 thumbnails. It emphasizes the importance of estimating performance using common numbers and thought experiments, as advocated by Jeff Dean from Google. The text provides examples of serial and parallel design alternatives, highlighting the significance of understanding system performance metrics and making informed design decisions. It concludes by emphasizing the importance of monitoring and measuring system components for accurate projections.</description></item><item><title>Google Pro Tip Use Back Of The Envelope Calculations</title><link>https://thakurajayL.github.io/quality-share/posts/google-pro-tip-use-back-of-the-envelope-calculations/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/google-pro-tip-use-back-of-the-envelope-calculations/</guid><description>The text discusses using back-of-the-envelope calculations to evaluate different design alternatives, specifically focusing on a scenario of generating an image results page with 30 thumbnails. It emphasizes the importance of estimating performance using common numbers and thought experiments, as advocated by Jeff Dean from Google. The text provides examples of serial and parallel design alternatives, highlighting the significance of understanding system performance metrics and making informed design decisions. It concludes by emphasizing the importance of monitoring and measuring system components for accurate projections.</description></item><item><title>In Search of an Understandable Consensus Algorithm (Extended Version)</title><link>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251028163446/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251028163446/</guid><description>Raft is a consensus algorithm developed as an alternative to Paxos, focusing on simplicity and understandability while providing equivalent results and efficiency. It simplifies the consensus problem into leader election, log replication, and safety, ensuring safety and consistency in distributed systems. Raft handles cluster membership changes efficiently and uses a strong leadership approach to simplify the algorithm. It has been shown to be easier to learn and implement compared to Paxos, with open-source implementations used by several companies. The algorithm ensures log entries are safely replicated and committed, handles leader election, and supports safe configuration changes. Raft&amp;rsquo;s approach prioritizes understandability, correctness, and performance, making it a practical foundation for system building.</description></item><item><title>In Search of an Understandable Consensus Algorithm (Extended Version)</title><link>https://thakurajayL.github.io/quality-share/posts/in-search-of-an-understandable-consensus-algorithm-extended-version/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/in-search-of-an-understandable-consensus-algorithm-extended-version/</guid><description>Raft is a consensus algorithm developed as an alternative to Paxos, focusing on simplicity and understandability while providing equivalent results and efficiency. It simplifies the consensus problem into leader election, log replication, and safety, ensuring safety and consistency in distributed systems. Raft handles cluster membership changes efficiently and uses a strong leadership approach to simplify the algorithm. It has been shown to be easier to learn and implement compared to Paxos, with open-source implementations used by several companies. The algorithm ensures log entries are safely replicated and committed, handles leader election, and supports safe configuration changes. Raft&amp;rsquo;s approach prioritizes understandability, correctness, and performance, making it a practical foundation for system building.</description></item><item><title>Root cause analysis from AWS</title><link>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251028000638/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/content-new-article-20251028000638/</guid><description>The Amazon DynamoDB service disruption in the Northern Virginia (US-EAST-1) Region on October 19 and 20, 2025, had three distinct periods of impact on customer applications. The disruption was triggered by a latent defect in the automated DNS management system of DynamoDB, causing increased API error rates. The issue was resolved by restoring DNS information. Additionally, the disruption affected Amazon EC2 instance launches, which experienced increased errors and latencies due to failures in the DropletWorkflow Manager system. Recovery involved re-establishing leases with droplets and propagating network configurations. The Network Load Balancer service also experienced connection errors due to health check failures, which were resolved by disabling automatic health check failovers. Other AWS services like Lambda functions, Amazon Elastic Container Service, and AWS Security Token Service were also impacted but recovered by addressing specific issues. AWS is implementing changes to prevent similar events in the future and improve service availability.</description></item><item><title>Root cause analysis from AWS</title><link>https://thakurajayL.github.io/quality-share/posts/root-cause-analysis-from-aws/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://thakurajayL.github.io/quality-share/posts/root-cause-analysis-from-aws/</guid><description>The Amazon DynamoDB service disruption in the Northern Virginia (US-EAST-1) Region on October 19 and 20, 2025, had three distinct periods of impact on customer applications. The disruption was triggered by a latent defect in the automated DNS management system of DynamoDB, causing increased API error rates. The issue was resolved by restoring DNS information. Additionally, the disruption affected Amazon EC2 instance launches, which experienced increased errors and latencies due to failures in the DropletWorkflow Manager system. Recovery involved re-establishing leases with droplets and propagating network configurations. The Network Load Balancer service also experienced connection errors due to health check failures, which were resolved by disabling automatic health check failovers. Other AWS services like Lambda functions, Amazon Elastic Container Service, and AWS Security Token Service were also impacted but recovered by addressing specific issues. AWS is implementing changes to prevent similar events in the future and improve service availability.</description></item></channel></rss>